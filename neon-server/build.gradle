/*
 * Copyright 2013 Next Century Corporation
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */


import com.ncc.neon.ElasticSearchJSONGenerator
import org.json.JSONArray
import com.ncc.neon.SparkSQLJSONGenerator
import com.ncc.neon.MongoJSONGenerator
import com.ncc.neon.JSONToCSVConverter
import org.gradle.api.plugins.jetty.internal.Monitor
import org.gradle.api.plugins.jetty.internal.JettyPluginWebAppContext

import java.text.SimpleDateFormat

buildscript {
    repositories {
        mavenCentral()
        flatDir {
            dirs 'gradle/plugins'
        }
    }
    dependencies {
        classpath "org.hidetake:gradle-ssh-plugin:$sshPluginVersion"
        classpath "org.apache.derby:derby:$derbyVersion"
        classpath "org.apache.derby:derbyclient:$derbyVersion"
    }
}

repositories {
    mavenCentral()
}

project.ext {
    testDataDir = "${projectDir}/src/test-data"

    // a mongo instance for inserting/deleting test data (will be lazy initialized)
    mongoInstance = null

    // used for determining when test data json needs to be generated
    testDataInputFileTree = fileTree('src/test-data').include('*.json')
}


apply plugin: 'jetty'
apply plugin: 'war'
apply plugin: 'signing'

// these files need to be applied in order since there are dependencies between them
apply from: "${rootDir}/gradle/sharedDependencies.gradle"
apply from: "gradle/sparkSQLDependencies.gradle"
apply from: "${rootDir}/gradle/js.gradle"
apply from: "gradle/integrationTest.gradle"
apply from: "gradle/acceptanceTest.gradle"
apply from: "gradle/signing.gradle"

apply from: "${rootDir}/gradle/groovy.gradle"
apply from: "${rootDir}/gradle/deploy.gradle"

sourceCompatibility = 1.7

configurations {
    // using slf4j
    compile.exclude module: 'commons-logging'
}

dependencies {
    compile "com.sun.jersey:jersey-servlet:$jerseyVersion"
    compile "com.sun.jersey:jersey-core:$jerseyVersion"
    compile "com.sun.jersey:jersey-client:$jerseyVersion"
    compile "com.sun.jersey:jersey-server:$jerseyVersion"
    compile "com.sun.jersey:jersey-json:$jerseyVersion"
    compile "com.sun.jersey.contribs:jersey-spring:$jerseyVersion"
    compile "org.springframework:spring-web:$springVersion"
    compile "org.slf4j:slf4j-api:$slf4jVersion"
    compile "org.slf4j:jcl-over-slf4j:$slf4jVersion"
    // TODO: Revisit this dependency.  In the migration from shark to spark-sql, one of the newer
    // library dependencies for spark-sql seems to cause a slf4j/log4j circular referencing issue.
    //compile 'org.slf4j:log4j-over-slf4j:1.7.2'
    compile "ch.qos.logback:logback-core:$logbackVersion"
    compile "ch.qos.logback:logback-classic:$logbackVersion"
    compile "com.google.guava:guava:$guavaVersion"
    compile "org.apache.poi:poi:$poiVersion"
    compile "org.apache.poi:poi-ooxml:$poiVersion"
    compile "org.apache.poi:poi-ooxml-schemas:$poiVersion"
    compile "org.apache.poi:ooxml-schemas:$ooxmlSchemasVersion"
    compile "org.apache.derby:derby:$derbyVersion"
    compile "org.apache.derby:derbyclient:$derbyVersion"

    compile "com.sun.jersey.contribs:jersey-multipart:$jerseyVersion"
    compile "com.monitorjbl:xlsx-streamer:$xlsxStreamerVersion"

    compile "commons-io:commons-io:$commonsIoVersion"
    compile("org.codehaus.groovy.modules.http-builder:http-builder:$httpBuilderVersion") {
        // we already include groovy-all
        exclude module: 'groovy'
    }
    compile "commons-lang:commons-lang:$commonsLangVersion"

    providedCompile "javax.servlet:javax.servlet-api:$javaxServletVersion"

    runtime "cglib:cglib:$cglibVersion"

    testCompile "junit:junit:$junitVersion"
    testCompile "commons-collections:commons-collections:$commonsCollectionsVersion"
    testCompile "org.springframework:spring-test:$springVersion"
}

war {
    dependsOn 'setVersion'
    description = 'Creates a war file for the project'
    from(jsOutputFolder) {
        into 'js'
    }
    doLast { task ->
        ant.checksum algorithm: "SHA-512", fileext: ".sha", file: task.archivePath
        ant.checksum algorithm: "MD5", fileext: ".md5", file: task.archivePath
    }
}

jettyRun {
    dependsOn gruntjs, watch, 'setVersion'
    reload = 'automatic'
    scanIntervalSeconds = 10
    httpPort = 8080

    webAppConfig = new JettyPluginWebAppContext()
    webAppConfig.baseResource = jettyRun.class.classLoader.loadClass('org.mortbay.resource.ResourceCollection').newInstance(
            [
                    file(webAppDirName).toString(),

                    // add the concatenated javascript so the widgets can access it by neon.js
                    buildDir.absolutePath,

                    // this lets us get to the examples directory using the /examples path, but unfortunately it also
                    // adds all of our base directories. this isn't really a problem just more clutter than is needed
                    rootDir.absolutePath
            ] as String[])

    doFirst {
        System.setProperty("log.dir", "${project.buildDir}/jettyRunLogs")
    }
}

[jettyRun, jettyStop]*.stopPort = 8081;
[jettyRun, jettyStop]*.stopKey = 'neon-jetty';

[jettyRun, jettyRunWar, transformTestWebService, acceptanceTestWar]*.with {
    /**
     * THIS IS A WORKAROUND FOR JETTY LOCKING STATIC HTML FILES ON WINDOWS
     *
     * When developing on Windows Jetty locks any static HTML files and resources, preventing on-the-fly
     * editing for quick development turn-around.  The work around for this is to override the
     * default setting for useFileMappedBuffer in jetty's webdefault.xml file.  Here we've extracted
     * the Jetty 6.1.25 webdefault.xml and simply set useFileMappedBuffer to false.
     *
     * References:
     * http://issues.gradle.org/browse/GRADLE-727
     * http://stackoverflow.com/questions/11032342/gradle-jetty-plugin-locking-files
     */
    webDefaultXml = file("${projectDir}/webdefault.xml")
}

[jettyRun, jettyRunWar, transformTestWebService, acceptanceTestWar]*.doLast {
    /**
     * THIS IS A WORKAROUND! THE CURRENT VERSION OF THIS TASK DOESN'T START A WATCHER IN DAEMON MODE
     *
     * If starting the monitor fails, it may be because the jetty task was updated to fix this issue
     * When that happens, we shouldn't need the custom task any more
     *
     * http://issues.gradle.org/browse/GRADLE-2263
     */
    if (getStopPort() != null && getStopPort() > 0 && getStopKey() != null) {
        Monitor monitor = new Monitor(getStopPort(), getStopKey(), server.getProxiedObject());
        monitor.start();
    }
}

test {
    description = "Runs the neon unit tests"
    def props = [:]
    props['unit.test'] = true
    props['mongo.host'] = getMongoHost()
    systemProperties props
}

task jacocoFullTestReport(type: JacocoReport) {
    description = "Generates the neon Jacoco test coverage report"
    group = JavaBasePlugin.VERIFICATION_GROUP
    dependsOn integrationTest

    executionData = files("$buildDir/jacoco/integrationTest.exec", "$buildDir/jacoco/test.exec")
    classDirectories = files(sourceSets.main.output.classesDir)
    sourceDirectories = files(sourceSets.main.output.classesDir)
}

// helper functions for generating data for the tests. this is used by several of the gradle files that configure the tests

task generateMongoJson {
    description = "Generates json files with mongo specific constructs that are used for validating mongo test results"
    def outputDir = "${testDataDir}/mongo-json"
    inputs.files { testDataInputFileTree }
    outputs.dir { outputDir }
    // mongo only needs the data files for input. it uses the rest of the standard json files for test verification
    doLast {
        def mongoJsonGenerator = new MongoJSONGenerator()
        mongoJsonGenerator.generateJson(testDataDir, outputDir, ~/data.json/)
    }
}

task generateSparkSQLJson {
    description = "Generates json files with spark sql specific constructs that are used for validating spark sql test results"
    def outputDir = "${testDataDir}/spark-json"
    inputs.files { testDataInputFileTree }
    outputs.dir { outputDir }
    doLast {
        // Use all files from testDataDir except types.json as that output is not based on data contents.
        // Instead it passes data types which are specific to each database and defined in the
        // test-data/<dbtype>-json/types.json files.
        new SparkSQLJSONGenerator().generateJson(testDataDir, outputDir, ~/(?!types).*\.json/)
    }
}

task generateSparkSQLCSV {
    description = "Generates csv files for inserting test data into spark sql"
    def outputDir = "${testDataDir}/spark-csv"
    def inputFile = new File(testDataDir, 'data.json')
    inputs.file { inputFile }
    outputs.dir { outputDir }

    doLast {
        JSONToCSVConverter.convertToCSV(
                new JSONArray(inputFile.text).toString(),
                new File("${outputDir}/data.csv"),
                new File("${outputDir}/fields.csv"),
                ['location'] as Set)
    }
}

task generateElasticSearchJson {
    description = "Generates json files with that are used for validating elasticsearch test results"
    def outputDir = "${testDataDir}/elasticsearch-json"
    logging.captureStandardOutput LogLevel.INFO
    inputs.files { testDataInputFileTree }
    outputs.dir { outputDir }
    doLast {
        // Use all files from testDataDir except types.json as that output is not based on data contents.
        // Instead it passes data types which are specific to each database and defined in the
        // test-data/<dbtype>-json/types.json files.
        new ElasticSearchJSONGenerator().generateJson(testDataDir, outputDir, ~/(?!types).*\.json/)
    }
    // /^(?!types)\.json/
}

task generateElasticSearchCSV {
    description = "Generates csv files for inserting test data into elasticsearch"
    def outputDir = "${testDataDir}/elasticsearch-csv"
    def inputFile = new File(testDataDir, 'data.json')
    inputs.file { inputFile }
    outputs.dir { outputDir }

    doLast {
        JSONToCSVConverter.convertToCSV(
                new JSONArray(inputFile.text).toString(),
                new File("${outputDir}/data.csv"),
                new File("${outputDir}/fields.csv"),
                ['location'] as Set)
    }
}

// if the host is not specified just use an empty string and neon will choose defaults
def getMongoHost() {
    return project.hasProperty("mongo.host") ? getProperty("mongo.host") : null
}

def getSparkSQLHost() {
    return project.hasProperty("sparksql.host") ? getProperty("sparksql.host") : null
}

def getElasticSearchHost() {
    return project.hasProperty("elasticsearch.host") ? getProperty("elasticsearch.host") : null
}

def getHdfsUrl() {
    return project.hasProperty("hdfs.url") ? getProperty("hdfs.url") : "hdfs://localhost:8020"
}

/* Get the version information, save it to resources directory
 *
 * Format:  0.7.5-32-g42770e9-2014.09.02
 *            ^    ^    ^        ^
 *            |    |    |        +  Date of build
 *            |    |    + shorted hash of git
 *            |    + Number of commits since last tag
 *            + Last tag
 */
task setVersion {
    def tagString = getTagName()
    def dateString = getDateString()
    writeVersionStringToPropertiesFile(tagString + "-" + dateString)
}

def getDateString() {
    SimpleDateFormat sdf = new SimpleDateFormat("yyyy.MM.dd")
    def dateString = new Date()
    return sdf.format(dateString)
}

def getTagName() {

    def stdout = new ByteArrayOutputStream()
    exec {
        // If Neon dir does not have .git/, or built on a system without git, this will fail.
	// This will continue anyway.
        ignoreExitValue = true
        commandLine 'git', 'describe', '--tags', '--long'
	// standardOutput is the default for output of a command line call; built into exec
        standardOutput = stdout
    }
    def tagString = stdout.toString().trim()
    if (tagString == null || tagString.length() == 0)
    {
       return version
    }
    def firstDash = tagString.indexOf("-")
    if (firstDash < 0)
    {
	return version
    }
    def newTagString = version + tagString.substring(firstDash)
    return newTagString
}

def writeVersionStringToPropertiesFile(versionString) {
    def versionfile = new File("${projectDir}/src/main/resources/version.properties")
    versionfile.text = 'build.version=' + versionString + "\n"
}

task buildNpmDist() {
    delete('dist')
    copy {
        from 'build/js'
        into 'dist'
        include 'neon-nodeps*.js'
        rename { String fileName ->
            fileName.replace('-nodeps', '')
        }
    }
    copy {
        from 'build/resources'
        into 'dist/resources'
        include '**/*.*'
    }
    copy {
        from 'build/libs'
        into 'dist/war'
        include '*.war'
    }
    copy {
        from './'
        into 'dist'
        include 'package.json'
        include 'typings.json'
    }
    copy {
        from 'src/typings'
        into 'dist'
        include 'index.d.ts'
    }
}

if (project.hasProperty("useElasticsearch1") && project.getProperty("useElasticsearch1") == "true") {
    sourceSets {
        main {
            groovy {
                exclude '**/ElasticSearch2*.groovy'
            }
        }
    }
} else {
    sourceSets {
        main {
            groovy {
                exclude '**/ElasticSearch1*.groovy'
            }
        }
    }
}

